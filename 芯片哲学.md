### 01-19
```
计算架构：
所有的微架构大概都能被归结成流处理
只有两种模块（储存与处理），两种连接（数据与代码），并且以储存分级别展开（local，global，...，RAM），CPU至少3级，GPU至少5级
怎么流，就是架构设计，保证流的属性（储存/处理 元件）（在架构上表现是，效率，功耗，复杂度等等）
离谱一点，内存里面的数据，本质上是用一个处理器去优化，取最终得到的结果，而自下而上设计的程序将这个过程完全变成确定性了
这也就是“执行”

是不是深度学习也能套用微架构范式呢？那么自上而下，怎么让过程尽可能的“可编程”，从优化变成“执行”

计算深度：
ppt上的数据“搬运”距离
一个宏观的缓存，编码解码TX-RX
另一个是电子移动距离我一直想不通
感觉是不是经过了transistor的多少呢？
如果程序非常复杂，电路一直没法“收敛”，就耗电
VDD到GND连接虽然看似很浅，但到运算就有“深度”了
没法收敛，电子一直在移动，（最简单的架构）当电子移动频率直接=时钟，那个功耗简直是当电热管用？

不标准微架构设计：
避免network-on-chip (a) Broadcast (b) 1D Multicast (c) 1D Systolic (d) Unicast
就像西瓜一样。干脆弄一大堆缓存把计算核心包起来，缓存中就放一些张量循环处理核心
计算核心是 芯（core），缓存是 瓤（mesh），张量循环处理核心是 子（mesh node）
不是模块化的，其中那些 配置/拓扑 是经过软件-硬件，co-op autoEDA模拟搜索出的最优配置

```
